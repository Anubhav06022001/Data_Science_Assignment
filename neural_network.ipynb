{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and Answers for \"Neural Network A Simple Perception\"\n",
    "\n",
    "1. **What is deep learning, and how is it connected to artificial intelligence?**\n",
    "   - **Answer**: Deep learning is a subset of machine learning that uses neural networks with many layers (deep neural networks) to analyze various data patterns. It is closely related to artificial intelligence (AI) as it enables machines to automatically learn from data and make decisions, contributing to AI advancements in tasks like image recognition, speech processing, and natural language understanding.\n",
    "\n",
    "2. **What is a neural network, and what are the different types of neural networks?**\n",
    "   - **Answer**: A neural network is a computational model inspired by the way biological neural networks in the human brain process information. Common types of neural networks include:\n",
    "     - **Feedforward Neural Networks (FNN)**\n",
    "     - **Convolutional Neural Networks (CNN)**\n",
    "     - **Recurrent Neural Networks (RNN)**\n",
    "     - **Generative Adversarial Networks (GAN)**\n",
    "\n",
    "3. **What is the mathematical structure of a neural network?**\n",
    "   - **Answer**: The mathematical structure of a neural network consists of layers of neurons. Each neuron in a layer is connected to neurons in the next layer via weighted connections, and each connection has an associated weight. The input data is processed through these layers, applying activation functions at each layer to produce the output.\n",
    "\n",
    "4. **What is an activation function, and why is it essential in neural networks?**\n",
    "   - **Answer**: An activation function determines the output of a neuron based on its input. It introduces non-linearity into the network, allowing it to learn complex patterns. Without activation functions, neural networks would only be able to perform linear transformations, making them incapable of handling complex tasks.\n",
    "\n",
    "5. **Could you list some common activation functions used in neural networks?**\n",
    "   - **Answer**: Some common activation functions include:\n",
    "     - **Sigmoid**\n",
    "     - **Tanh**\n",
    "     - **ReLU (Rectified Linear Unit)**\n",
    "     - **Leaky ReLU**\n",
    "     - **Softmax**\n",
    "\n",
    "6. **What is a multilayer neural network?**\n",
    "   - **Answer**: A multilayer neural network consists of an input layer, one or more hidden layers, and an output layer. The hidden layers allow the network to model complex relationships by combining features from the input layer.\n",
    "\n",
    "7. **What is a loss function, and why is it crucial for neural network training?**\n",
    "   - **Answer**: A loss function measures the difference between the predicted output and the actual output (ground truth). It is crucial for training because it provides feedback to adjust the model's weights during optimization.\n",
    "\n",
    "8. **What are some common types of loss functions?**\n",
    "   - **Answer**: Some common loss functions include:\n",
    "     - **Mean Squared Error (MSE)** for regression tasks\n",
    "     - **Binary Cross-Entropy** for binary classification tasks\n",
    "     - **Categorical Cross-Entropy** for multi-class classification tasks\n",
    "\n",
    "9. **How does a neural network learn?**\n",
    "   - **Answer**: A neural network learns through an optimization process, typically using a method like gradient descent, where the model’s weights are adjusted to minimize the loss function. This process involves forward propagation, where the input data passes through the network, and backward propagation, where the gradients of the loss with respect to the weights are calculated.\n",
    "\n",
    "10. **What is an optimizer in neural networks, and why is it necessary?**\n",
    "    - **Answer**: An optimizer is an algorithm used to minimize the loss function by updating the model's weights. It is necessary because it ensures that the network converges to a minimum loss during training.\n",
    "\n",
    "11. **Could you briefly describe some common optimizers?**\n",
    "    - **Answer**: Some common optimizers include:\n",
    "      - **Stochastic Gradient Descent (SGD)**\n",
    "      - **Adam**\n",
    "      - **RMSProp**\n",
    "\n",
    "12. **Can you explain forward and backward propagation in a neural network?**\n",
    "    - **Answer**: Forward propagation refers to the process of passing input data through the network to obtain an output. Backward propagation involves calculating the gradients of the loss function with respect to the weights and using these gradients to update the weights during training.\n",
    "\n",
    "13. **What is weight initialization, and how does it impact training?**\n",
    "    - **Answer**: Weight initialization refers to the process of setting the initial values for the weights of a neural network before training. Proper weight initialization helps avoid issues such as slow convergence and vanishing/exploding gradients during training.\n",
    "\n",
    "14. **What is the vanishing gradient problem in deep learning?**\n",
    "    - **Answer**: The vanishing gradient problem occurs when gradients become too small as they propagate backward through the network, making it difficult for the model to update the weights properly and slowing down learning.\n",
    "\n",
    "15. **What is the exploding gradient problem?**\n",
    "    - **Answer**: The exploding gradient problem occurs when gradients become too large, causing the weights to become unstable and leading to a failure in model convergence.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.model import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Practical Part\n",
    "\n",
    "1. **How do you create a simple perceptron for basic binary classification?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7333 - loss: 0.8792 \n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7049 \n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.7316 \n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7257 \n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0620     \n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6337 \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5653 \n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.7796 \n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8929 \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6235 \n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6326 \n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6232 \n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7028 \n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5642 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5586 \n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0466     \n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.7020 \n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.7876\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0050     \n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.7207 \n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9000 - loss: 0.6826\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.7758\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.7256 \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8596 \n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6297 \n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6211 \n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8697 \n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0032     \n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0734     \n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9000 - loss: 0.5623\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.7832 \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8384 \n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0005     \n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6361 \n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5568 \n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6985 \n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6271 \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8333 - loss: 0.6982\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 0.7179\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6265 \n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.6977 \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7139 \n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8333 - loss: 0.6185\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.9946     \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5559 \n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.7160 \n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5556 \n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.9896     \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.7179 \n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9000 - loss: 0.6859\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.8614\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6171 \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5591 \n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6766 \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7671 \n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8456 \n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.6448 \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7089 \n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7661 \n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0289     \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7732 \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6828 \n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0495     \n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8570 \n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0480     \n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0509     \n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0242     \n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.7710\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5535 \n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8394 \n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8546 \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6198 \n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.6196\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5333 - loss: 0.9760    \n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8372 \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8627 \n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8245 \n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7677 \n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6184 \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7670 \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 1.0165     \n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0416     \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7600 \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6774 \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6770 \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5333 - loss: 0.9722     \n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0081     \n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0075     \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.7065 \n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 1.0340     \n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6371 \n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.7058 \n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.7627 \n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5333 - loss: 0.9659    \n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.6108\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6879 \n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.9645     \n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.8182 \n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 1.0292     \n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.8523 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f5edd655e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_dim=2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Training data for a simple AND operation\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Convert to NumPy array\n",
    "y = np.array([0, 0, 0, 1])                      # Convert to NumPy array\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **How can you build a neural network with one hidden layer using Keras?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2667 - loss: 0.7373     \n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.7427 \n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7689     \n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7333 - loss: 0.7327 \n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.7320 \n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.6925 \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.6910\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7825     \n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6933 \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6877 \n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6755 \n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.7241 \n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6842 \n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6506 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6883 \n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6874 \n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6864 \n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6684 \n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6826 \n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7512     \n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9000 - loss: 0.6441\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8333 - loss: 0.6582\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6781 \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6796 \n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.7097 \n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.7085 \n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6913 \n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6375 \n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6515 \n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6351 \n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6702 \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5333 - loss: 0.7491    \n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7475     \n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6519 \n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6664 \n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7446     \n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7333     \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7321     \n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6275 \n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6645 \n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6768 \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6757 \n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7436     \n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5333 - loss: 0.7260    \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8333 - loss: 0.6568\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6942 \n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6935 \n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.6192 \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6564 \n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6553 \n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6545 \n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6340 \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6640 \n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6285 \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7159     \n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.7299     \n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6300 \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6763 \n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7209     \n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6084 \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6411 \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6550 \n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6539 \n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6703 \n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7333 - loss: 0.6747\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.6682\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7033     \n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 0.6657\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6652 \n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7001     \n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6466 \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7132     \n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7060     \n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6959     \n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6592 \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7027     \n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6088 \n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9000 - loss: 0.5926\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5333 - loss: 0.6920    \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5333 - loss: 0.6905    \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6224 \n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6263 \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6029 \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7011     \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6996     \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6982     \n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.6106 \n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8333 - loss: 0.6155 \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6514 \n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.6074 \n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6883     \n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8333 - loss: 0.6261\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6048 \n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5933 \n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6841     \n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5333 - loss: 0.6881     \n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6376 \n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6204 \n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5746 \n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5333 - loss: 0.6847     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f5edc2411f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=5, input_dim=2, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Output layer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=100, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **How do you initialize weights using the Xavier (Glorot) initialization method in Keras?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=5, input_dim=2, activation='relu', kernel_initializer=GlorotUniform()))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. **How can you apply different activation functions in a neural network in Keras?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=5, input_dim=2, activation='tanh'))  # Tanh activation\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Sigmoid activation for output\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **How do you add dropout to a neural network model to prevent overfitting?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=5, input_dim=2, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **How do you manually implement forward propagation in a simple neural network?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37754067 0.64565631 0.5        0.52497919]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def forward_propagation(X, weights, biases):\n",
    "    return sigmoid(np.dot(X, weights) + biases)\n",
    "\n",
    "# Sample input\n",
    "X = np.array([[0, 1], [1, 0], [1, 1], [0, 0]])\n",
    "weights = np.array([0.5, -0.6])\n",
    "biases = np.array([0.1])\n",
    "\n",
    "predictions = forward_propagation(X, weights, biases)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **How do you add batch normalization to a neural network model in Keras?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=5, input_dim=2, activation='relu'))\n",
    "model.add(BatchNormalization())  # Batch normalization\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **How can you visualize the training process with accuracy and loss curves?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 0.6941 \n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6927     \n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.6908 \n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6893 \n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6876 \n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6807 \n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7333 - loss: 0.6838\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6821 \n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6751 \n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6909     \n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6908     \n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6680 \n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6905     \n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6723 \n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6538 \n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6904     \n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5333 - loss: 0.6903     \n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6903     \n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6513 \n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6391 \n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6904     \n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6438 \n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5333 - loss: 0.6905     \n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6905     \n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 0.6551\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6906     \n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6328 \n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7333 - loss: 0.6505\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9000 - loss: 0.6138 \n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.6105 \n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6229 \n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.6208 \n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6920     \n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.6001 \n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.6145 \n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6927     \n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7333 - loss: 0.6382 \n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6931     \n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5877 \n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6344 \n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6941     \n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5802 \n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5987 \n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5967 \n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.6956     \n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.6959     \n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5683 \n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5333 - loss: 0.6968    \n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7333 - loss: 0.6244\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5613 \n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5840 \n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5822 \n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6201 \n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5520 \n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5770 \n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6172 \n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5456 \n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5431 \n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6143 \n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5691 \n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5372 \n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5658 \n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5331 \n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7050     \n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7053     \n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8333 - loss: 0.5607 \n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7064     \n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5248 \n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7077     \n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.5211\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5333 - loss: 0.7089    \n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6048 \n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.6042 \n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5142 \n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.5120 \n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.5100 \n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5455 \n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7135     \n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.6004 \n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.5999 \n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7149     \n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.5017 \n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.4996 \n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9000 - loss: 0.4978 \n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7180     \n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8333 - loss: 0.5359 \n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7190     \n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9000 - loss: 0.4929 \n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.5953 \n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7208     \n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5333 - loss: 0.7213     \n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.5943 \n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8333 - loss: 0.5295\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8333 - loss: 0.5284\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8333 - loss: 0.5273 \n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.5925 \n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7333 - loss: 0.5922 \n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7259     \n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7333 - loss: 0.5916 \n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5333 - loss: 0.7270     \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(X, y, epochs=100, batch_size=1)\n",
    "   \n",
    "# Plotting accuracy and loss\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **How can you use gradient clipping in Keras to control the gradient size and prevent exploding gradients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=5,\n",
    "                \n",
    "input_dim=2, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(clipvalue=1.0)  # Clip gradients to max value of 1.0\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **How can you create a custom loss function in Keras?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "model.compile(loss=custom_loss, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "11. **How can you visualize the structure of a neural network model in Keras?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=5, input_dim=2, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "plot_model(model, to_file='model_structure.png', show_shapes=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
