{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308600ad",
   "metadata": {},
   "source": [
    "\n",
    "## **Deep Learning Frameworks**\n",
    "\n",
    "### **Q1: What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?**\n",
    "**A1:** TensorFlow 2.0 is a more user-friendly and streamlined version of TensorFlow that emphasizes simplicity and ease of use. It integrates Keras as its high-level API, provides eager execution as default, and simplifies APIs compared to TensorFlow 1.x, which relied heavily on static computation graphs.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2: How do you install TensorFlow 2.0?**\n",
    "**A2:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b2cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "Requirement already satisfied: tensorflow==2.2.0 in /home/anubhav/.local/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.1.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (5.26.1)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/lib/python3/dist-packages (from tensorflow==2.2.0) (1.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.2.0) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.68.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (0.41.3)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (68.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/anubhav/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/anubhav/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/anubhav/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/anubhav/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anubhav/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2019.11.28)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/anubhav/.local/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/anubhav/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc85c8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **Q3: What is the primary function of the `tf.function` in TensorFlow 2.0?**\n",
    "**A3:** The `tf.function` decorator is used to convert Python functions into TensorFlow computational graphs, allowing for optimized and faster execution.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4: What is the purpose of the `Model` class in TensorFlow 2.0?**\n",
    "**A4:** The `Model` class in TensorFlow 2.0 provides a flexible interface for defining and training neural networks. It serves as a base for creating custom models and managing layers, training loops, and optimizations.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q5: How do you create a neural network using TensorFlow 2.0?**\n",
    "**A5:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(100,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6babf",
   "metadata": {},
   "source": [
    "### **Q6: What is the importance of Tensor Space in TensorFlow?**\n",
    "**A6:** Tensor space represents the multi-dimensional arrays that TensorFlow uses for computations. Understanding this helps in designing and debugging models efficiently.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q7: How can TensorBoard be integrated with TensorFlow 2.0?**\n",
    "**A7:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "model.fit(x_train, y_train, epochs=5, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d4ad58",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "---\n",
    "\n",
    "### **Q8: What is TensorFlow Playground?**\n",
    "**A8:** TensorFlow Playground is an interactive, web-based visualization tool to experiment with and understand neural networks.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q9: What is Netron, and how is it useful for deep learning models?**\n",
    "**A9:** Netron is a visualizer for neural network models that supports various formats. It helps developers debug and understand model architecture.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q10: What is the difference between TensorFlow and PyTorch?**\n",
    "**A10:** TensorFlow emphasizes production and deployment, while PyTorch is designed for research and ease of experimentation with dynamic computation graphs.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q11: How do you install PyTorch?**\n",
    "**A11:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c2399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.1%2Bcu118-cp38-cp38-linux_x86_64.whl (857.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 857.6 MB 3.9 MB/s eta 0:00:0112  |▌                               | 12.1 MB 1.4 MB/s eta 0:10:04MB 15.4 MB/s eta 0:00:41     |██████████▎                     | 276.7 MB 1.4 MB/s eta 0:06:58    |██████████▊                     | 287.1 MB 5.3 MB/s eta 0:01:48      | 307.9 MB 4.1 MB/s eta 0:02:15��████████▍                   | 330.8 MB 4.4 MB/s eta 0:02:00��████████▍                   | 333.2 MB 1.9 MB/s eta 0:04:372.2 MB/s eta 0:03:50███▏                 | 379.8 MB 4.2 MB/s eta 0:01:54███▍                 | 386.2 MB 2.0 MB/s eta 0:04:01███▉                 | 397.4 MB 6.6 MB/s eta 0:01:11████                 | 400.5 MB 594 kB/s eta 0:12:49  | 437.2 MB 1.8 MB/s eta 0:03:51███████▌              | 469.7 MB 25.5 MB/s eta 0:00:16[K     |██████████████████▎             | 490.0 MB 6.2 MB/s eta 0:00:59[K     |██████████████████▍             | 494.2 MB 3.5 MB/s eta 0:01:43[K     |██████████████████▋             | 499.7 MB 1.7 MB/s eta 0:03:29[K     |███████████████████             | 507.6 MB 7.0 MB/s eta 0:00:50   | 521.1 MB 5.4 MB/s eta 0:01:03   | 531.2 MB 1.5 MB/s eta 0:03:43�█████████           | 562.5 MB 5.7 MB/s eta 0:00:52��████████████████████▏          | 567.5 MB 5.5 MB/s eta 0:00:53��████████████████████▏          | 568.3 MB 5.5 MB/s eta 0:00:53��████████████████████▎          | 570.2 MB 5.5 MB/s eta 0:00:52��████████████████████▌          | 575.3 MB 3.5 MB/s eta 0:01:22��████████████████████▉          | 584.1 MB 4.8 MB/s eta 0:00:58:00:09MB 4.8 MB/s eta 0:00:54█████         | 616.9 MB 159.0 MB/s eta 0:00:02�██████████▎        | 623.5 MB 28.4 MB/s eta 0:00:09█████▊        | 636.6 MB 1.3 MB/s eta 0:02:55�███████████        | 645.9 MB 11.3 MB/s eta 0:00:19��████████████████▋       | 658.3 MB 6.2 MB/s eta 0:00:33��████████████████▉       | 664.7 MB 5.4 MB/s eta 0:00:36��█████████████████       | 668.9 MB 6.2 MB/s eta 0:00:31 | 700.4 MB 727 kB/s eta 0:03:37�████████▍     | 708.3 MB 1.1 MB/s eta 0:02:13 | 709.5 MB 1.1 MB/s eta 0:02:12     |██████████████████████████▋     | 713.2 MB 5.8 MB/s eta 0:00:25�████████▉     | 719.6 MB 1.9 MB/s eta 0:01:133 | 725.1 MB 5.0 MB/s eta 0:00:27��████████▎    | 729.8 MB 6.8 MB/s eta 0:00:19��████████▊    | 741.7 MB 3.1 MB/s eta 0:00:38��████████▉    | 745.6 MB 4.1 MB/s eta 0:00:28��█████████    | 747.8 MB 4.1 MB/s eta 0:00:27��█████████    | 752.9 MB 3.4 MB/s eta 0:00:31��███████████████████▋   | 767.2 MB 2.2 MB/s eta 0:00:41��███████████████████▋   | 767.7 MB 2.2 MB/s eta 0:00:41��███████████████████▊   | 770.2 MB 2.2 MB/s eta 0:00:40��███████████████████▉   | 772.2 MB 1.5 MB/s eta 0:00:57��███████████████████▉   | 773.7 MB 1.5 MB/s eta 0:00:56��████████████████████   | 774.3 MB 1.5 MB/s eta 0:00:55��████████████████████   | 777.0 MB 1.5 MB/s eta 0:00:54��████████████████████   | 777.5 MB 33.2 MB/s eta 0:00:03    |█████████████████████████████▌  | 790.9 MB 905 kB/s eta 0:01:142 MB 4.4 MB/s eta 0:00:118 MB 4.2 MB/s eta 0:00:128 MB 4.2 MB/s eta 0:00:11�█▌ | 816.8 MB 53.1 MB/s eta 0:00:01�█▋ | 820.1 MB 53.1 MB/s eta 0:00:010 MB 1.3 MB/s eta 0:00:23███████▏| 834.7 MB 7.5 MB/s eta 0:00:04███████▎| 839.7 MB 2.0 MB/s eta 0:00:09�█████████████████████████▌| 845.4 MB 3.8 MB/s eta 0:00:04███████▋| 848.6 MB 3.8 MB/s eta 0:00:03███████▊| 850.6 MB 1.4 MB/s eta 0:00:05████████| 855.0 MB 1.4 MB/s eta 0:00:02"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d7c55",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "---\n",
    "\n",
    "### **Q12: What is the basic structure of a PyTorch neural network2**\n",
    "**A12:** \n",
    "The basic structure of a PyTorch neural network consists of the following components:\n",
    "\n",
    "**Model Class:** Define a custom class for your neural network that inherits from torch.nn.Module. This class represents the architecture of the network.\n",
    "\n",
    "**Layers:** Specify the layers in the __init__ method of the class. Common layers include nn.Linear (for fully connected layers), nn.Conv2d (for convolutional layers), and nn.ReLU (for activation functions).\n",
    "\n",
    "**Forward Method:** Implement the forward method to define the forward pass. This method takes input data and defines how it flows through the layers to produce the output.\n",
    "\n",
    "**Backward Pass:** Handled automatically by PyTorch's autograd system when you calculate the loss and call loss.backward().\n",
    "\n",
    "---\n",
    "\n",
    "### **Q13: What is the significance of tensors in PyTorch?**\n",
    "**A13:** Tensors are a fundamental data structure in PyTorch and play a critical role in its functionality. Here’s why they are significant:\n",
    "\n",
    "### **1. Core Data Structure**\n",
    "Tensors are multi-dimensional arrays, similar to NumPy arrays, but with additional capabilities that make them suitable for deep learning tasks. They store data for input, output, and intermediate computations in PyTorch models.\n",
    "\n",
    "### **2. Hardware Acceleration**\n",
    "Tensors can seamlessly move between CPUs and GPUs. Operations on tensors can leverage GPU acceleration for faster computations, making them ideal for training deep learning models.\n",
    "\n",
    "### **3. Efficient Mathematical Operations**\n",
    "PyTorch provides a wide range of optimized mathematical operations on tensors, including linear algebra, matrix manipulations, and element-wise computations, essential for deep learning algorithms.\n",
    "\n",
    "### **4. Autograd and Gradients**\n",
    "Tensors support PyTorch's automatic differentiation feature (`autograd`). By enabling gradient tracking, tensors help compute gradients during backpropagation, simplifying model optimization.\n",
    "\n",
    "### **5. Compatibility with Neural Networks**\n",
    "Tensors are a fundamental data structure in PyTorch and play a critical role in its functionality. Here’s why they are significant:\n",
    "\n",
    "1. Core Data Structure\n",
    "Tensors are multi-dimensional arrays, similar to NumPy arrays, but with additional capabilities that make them suitable for deep learning tasks. They store data for input, output, and intermediate computations in PyTorch models.\n",
    "\n",
    "2. Hardware Acceleration\n",
    "Tensors can seamlessly move between CPUs and GPUs. Operations on tensors can leverage GPU acceleration for faster computations, making them ideal for training deep learning models.\n",
    "\n",
    "3. Efficient Mathematical Operations\n",
    "PyTorch provides a wide range of optimized mathematical operations on tensors, including linear algebra, matrix manipulations, and element-wise computations, essential for deep learning algorithms.\n",
    "\n",
    "4. Autograd and Gradients\n",
    "Tensors support PyTorch's automatic differentiation feature (autograd). By enabling gradient tracking, tensors help compute gradients during backpropagation, simplifying model optimization.\n",
    "\n",
    "5. Compatibility with Neural Networks\n",
    "Tensors are the primary data type for passing inputs, weights, and activations in neural network layers. They integrate seamlessly with PyTorch's torch.nn module.\n",
    "\n",
    "Tensors provide the foundation for all computations in PyTorch, making them indispensable for building and training machine learning models.\n",
    "\n",
    "---\n",
    "### **Q14: What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch**\n",
    "**A14:** The difference between torch.Tensor and torch.cuda.Tensor in PyTorch lies in where the tensors are stored and how they are utilized for computation:\n",
    "\n",
    "**1. torch.Tensor**\n",
    "\n",
    "Description: The default tensor type in PyTorch, which resides in the CPU memory.\n",
    "\n",
    "Usage: Suitable for computations that don't require GPU acceleration.\n",
    "\n",
    "Creation: By default, tensors created using torch.tensor() or similar methods are of type torch.Tensor.\n",
    "\n",
    "Performance: Operations are performed on the CPU, which may be slower for large-scale computations.\n",
    "\n",
    "**2. torch.cuda.Tensor**\n",
    "\n",
    "Description: A tensor that resides in the GPU memory, specifically designed for GPU-accelerated computations.\n",
    "\n",
    "Usage: Used to leverage GPU for faster computations, especially in deep learning tasks.\n",
    "\n",
    "Creation: Created by explicitly moving a tensor to the GPU using .to('cuda') or .cuda() methods.\n",
    "\n",
    "Performance: Operations on torch.cuda.Tensor are significantly faster on compatible GPUs.\n",
    "\n",
    "\n",
    "In summary, torch.cuda.Tensor enables GPU utilization for faster computations, whereas torch.Tensor is for CPU-based tasks. Use torch.cuda.Tensor when working with large-scale or deep learning models to maximize performance.\n",
    "\n",
    "---\n",
    "### **Q15:What is the purpose of the torch.optim module in PyTorch?**\n",
    "**A15:**The `torch.optim` module in PyTorch provides a collection of optimization algorithms for training neural networks. Its primary purpose is to adjust the parameters (weights) of a model to minimize the loss function and improve model performance during training.\n",
    "\n",
    "### Key Features:\n",
    "1. **Predefined Optimizers**: Includes popular optimization algorithms like SGD, Adam, RMSprop, etc.\n",
    "2. **Parameter Management**: Allows easy specification and management of model parameters to be updated.\n",
    "3. **Learning Rate Scheduling**: Supports dynamic adjustment of learning rates through schedulers.\n",
    "4. **Customizability**: Enables customization of optimization behavior by tweaking hyperparameters like learning rate, momentum, weight decay, etc.\n",
    "\n",
    "\n",
    "---\n",
    "### **Q16:What are some common activation functions used in neural networks?**\n",
    "**A16:**Activation functions introduce non-linearity into a neural network, allowing it to learn complex patterns in data. Below are some commonly used activation functions:\n",
    "\n",
    "### 1. **ReLU (Rectified Linear Unit)**\n",
    "- **Formula**: `f(x) = max(0, x)`\n",
    "- **Advantages**: Simple, computationally efficient, and helps mitigate the vanishing gradient problem.\n",
    "- **Use Case**: Commonly used in hidden layers of deep networks.\n",
    "\n",
    "### 2. **Sigmoid**\n",
    "- **Formula**: `f(x) = 1 / (1 + exp(-x))`\n",
    "- **Advantages**: Outputs values between 0 and 1, making it useful for probabilistic interpretations.\n",
    "- **Use Case**: Often used in the output layer for binary classification.\n",
    "\n",
    "### 3. **Tanh (Hyperbolic Tangent)**\n",
    "- **Formula**: `f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))`\n",
    "- **Advantages**: Outputs values between -1 and 1, providing zero-centered activation.\n",
    "- **Use Case**: Suitable for hidden layers in certain tasks.\n",
    "\n",
    "### 4. **Softmax**\n",
    "- **Formula**: `f(x)_i = exp(x_i) / sum(exp(x_j))`\n",
    "- **Advantages**: Converts logits into probabilities that sum to 1.\n",
    "- **Use Case**: Commonly used in the output layer for multi-class classification.\n",
    "\n",
    "### 5. **Leaky ReLU**\n",
    "- **Formula**: `f(x) = x if x > 0, else alpha * x`\n",
    "- **Advantages**: Addresses the \"dying ReLU\" problem by allowing small gradients for negative inputs.\n",
    "- **Use Case**: Similar use cases as ReLU but better for deeper networks.\n",
    "\n",
    "### 6. **ELU (Exponential Linear Unit)**\n",
    "- **Formula**: `f(x) = x if x > 0, else alpha * (exp(x) - 1)`\n",
    "- **Advantages**: Smooth and helps avoid vanishing gradients for small inputs.\n",
    "- **Use Case**: Variants of ELU are often explored in deep learning.\n",
    "\n",
    "### 7. **Swish**\n",
    "- **Formula**: `f(x) = x / (1 + exp(-x))`\n",
    "- **Advantages**: Smooth and self-gated, often yields better performance in deep networks.\n",
    "- **Use Case**: Modern architectures like EfficientNet use Swish.\n",
    "\n",
    "### Summary\n",
    "Each activation function has specific strengths and use cases. Choosing the right one depends on the task and network architecture.\n",
    "\n",
    "---\n",
    "### **Q17: What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?**\n",
    "**A17:****torch.nn.Module:**\n",
    "- **Description**: The base class for all neural network models in PyTorch.\n",
    "\n",
    "- **Flexibility**: Allows for custom architectures, control over forward passes, and advanced computations.\n",
    "\n",
    "- **Use Case**: When building complex or non-linear architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(10, 20)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(20, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b43f5a",
   "metadata": {},
   "source": [
    "\n",
    "**2. torch.nn.Sequential:**\n",
    "\n",
    "Description: A container for stacking layers in a sequential manner.\n",
    "\n",
    "Simplicity: Best for straightforward, feed-forward architectures.\n",
    "\n",
    "Use Case: When the model architecture is linear without requiring control over intermediate computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b19f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e13529",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **Q18: How can you monitor training progress in TensorFlow 2.0?**\n",
    "**A18:**1. Using Callbacks:\n",
    "TensorFlow provides the tf.keras.callbacks module to monitor training progress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db573de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example callback to log training progress\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "# Training\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba53df",
   "metadata": {},
   "source": [
    "TensorBoard: Visualize metrics like loss, accuracy, and more.\n",
    "\n",
    "EarlyStopping: Stop training if no improvement is observed\n",
    "\n",
    "2. Manual Monitoring:\n",
    "\n",
    "Log metrics during training using custom code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    history = model.fit(x_train, y_train, verbose=0)\n",
    "    print(f\"Epoch {epoch + 1}: Loss = {history.history['loss'][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00451ac7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **Q19:  How does the Keras API fit into TensorFlow 2.0?**\n",
    "**A19:** The Keras API is integrated into TensorFlow 2.0 as its high-level API for building and training models.\n",
    "\n",
    "**Features:**\n",
    "\n",
    "Ease of Use: Simple syntax for defining layers and models.\n",
    "\n",
    "Flexibility: Supports Sequential, Functional, and Subclassing APIs.\n",
    "\n",
    "Interoperability: Fully integrated with TensorFlow functionalities like tf.data, tf.function, and distribution strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e386de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(100,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506e5dab",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **Q20: What is an example of a deep learning project that can be implemented using TensorFlow 2.0?**\n",
    "**A20:** One example is building an Image Classification Model using the CIFAR-10 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2a3d0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### **Q21: What is the main advantage of using pre-trained models in TensorFlow and PyTorch?**\n",
    "**A21:** Pre-trained models provide a significant advantage by reducing the time and computational cost required to train deep learning models from scratch.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "Faster Development: Pre-trained models are already trained on large datasets and require only fine-tuning.\n",
    "\n",
    "Better Performance: Leverage learned features for tasks like classification, object detection, or NLP.\n",
    "\n",
    "Reduced Data Requirements: Effective for tasks with limited labeled data.\n",
    "\n",
    "Pre-trained models are widely used in applications like image recognition, text classification, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654aa539",
   "metadata": {},
   "source": [
    "\n",
    "## **Practical**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9805e3",
   "metadata": {},
   "source": [
    "\n",
    "### **Q1: How do you install and verify that TensorFlow 2.0 was installed successfully?**\n",
    "**Solution:**\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337efd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "Collecting tensorflow==2.2.0\n",
      "  Downloading tensorflow-2.2.0-cp38-cp38-manylinux2010_x86_64.whl (516.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 516.3 MB 996 bytes/s  0:00:011    |████████████                    | 193.1 MB 1.0 MB/s eta 0:05:09     |█████████████████               | 274.9 MB 2.9 MB/s eta 0:01:23     |██████████████████▌             | 299.1 MB 5.9 MB/s eta 0:00:38[K     |██████████████████▊             | 302.3 MB 1.6 MB/s eta 0:02:14   | 313.9 MB 1.8 MB/s eta 0:01:53   | 324.3 MB 3.0 MB/s eta 0:01:05��████████████████████▍          | 345.8 MB 1.7 MB/s eta 0:01:41��████████████████████▉          | 352.9 MB 4.5 MB/s eta 0:00:37MB 249 kB/s eta 0:10:11█████▊        | 382.5 MB 514 kB/s eta 0:04:21��████████████████▉       | 401.2 MB 936 kB/s eta 0:02:03�████████▏     | 422.0 MB 4.7 MB/s eta 0:00:21 | 424.0 MB 4.7 MB/s eta 0:00:20     |███████████████████████████▏    | 438.8 MB 501 kB/s eta 0:02:35[K     |███████████████████████████▊    | 446.6 MB 3.2 MB/s eta 0:00:22████████▎   | 455.5 MB 4.8 MB/s eta 0:00:13��████████████████████████▍   | 458.8 MB 12.5 MB/s eta 0:00:05█████████████████████████████▏  | 470.3 MB 3.5 MB/s eta 0:00:13█████████████████████████████▎  | 472.0 MB 3.5 MB/s eta 0:00:13    |█████████████████████████████▋  | 478.6 MB 3.4 MB/s eta 0:00:12�███████████████████████████▊  | 478.9 MB 3.4 MB/s eta 0:00:11█████████████████████████████▉  | 481.0 MB 4.0 MB/s eta 0:00:09��█████████████████████████▉  | 481.3 MB 4.0 MB/s eta 0:00:09██████████████████████████████  | 483.6 MB 295 kB/s eta 0:01:51██████████████████████████████  | 484.5 MB 295 kB/s eta 0:01:486 MB 3.6 MB/s eta 0:00:082 MB 2.7 MB/s eta 0:00:09██████ | 498.6 MB 2.7 MB/s eta 0:00:071 MB 2.7 MB/s eta 0:00:07███████▍| 506.4 MB 5.1 MB/s eta 0:00:02��███████████▋| 509.6 MB 18.4 MB/s eta 0:00:01�█████████████████████████▊| 511.4 MB 5.9 MB/s eta 0:00:01�████████████████▊| 511.7 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (2.1.0)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 159 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 120 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (1.24.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 28 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (5.26.1)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/lib/python3/dist-packages (from tensorflow==2.2.0) (1.11.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.2.0) (1.14.0)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.68.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/anubhav/.local/lib/python3.8/site-packages (from tensorflow==2.2.0) (0.41.3)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 66 kB/s  eta 0:00:01��██████████████████▌           | 16.7 MB 3.1 MB/s eta 0:00:03  | 21.7 MB 710 kB/s eta 0:00:07��███████████████████▉    | 22.7 MB 710 kB/s eta 0:00:05██████████████████▎   | 23.0 MB 710 kB/s eta 0:00:05��█████████████████████████▋  | 24.1 MB 710 kB/s eta 0:00:03�█████████████  | 24.4 MB 6.0 MB/s eta 0:00:0125.4 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 9.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (68.2.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/anubhav/.local/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.1)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.1)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/anubhav/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anubhav/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2019.11.28)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/anubhav/.local/lib/python3.8/site-packages (from werkzeug>=0.11.15->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.1.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/anubhav/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.17.0)\n",
      "\u001b[31mERROR: scikit-image 0.21.0 has requirement scipy>=1.8, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: scikit-learn 1.3.2 has requirement scipy>=1.5.0, but you'll have scipy 1.4.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: astunparse, gast, google-pasta, h5py, keras-preprocessing, opt-einsum, grpcio, cachetools, rsa, google-auth, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard-plugin-wit, tensorboard, tensorflow-estimator, termcolor, scipy, tensorflow\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "Successfully installed astunparse-1.6.3 cachetools-4.2.4 gast-0.3.3 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.68.1 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.7 opt-einsum-3.4.0 requests-oauthlib-2.0.0 rsa-4.9 scipy-1.4.1 tensorboard-2.2.2 tensorboard-plugin-wit-1.8.1 tensorflow-2.2.0 tensorflow-estimator-2.2.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28833e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d135d3",
   "metadata": {},
   "source": [
    "### **Q2: How can you define a simple function in TensorFlow 2.0 to perform addition?**\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f6a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "print(add(3, 4).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0e8cf",
   "metadata": {},
   "source": [
    " \n",
    "### **Q3: How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?**\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(784,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16013da3",
   "metadata": {},
   "source": [
    "### **Q4: How can you visualize the training progress using TensorFlow and Matplotlib?**\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebe21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.2, epochs=10)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.2, epochs=10)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1360b",
   "metadata": {},
   "source": [
    "### **Q5: How do you install PyTorch and verify the PyTorch installation?**\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d2f7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 797.1 MB 3.0 kB/s eta 0:00:01     |██████████████████              | 447.3 MB 1.6 MB/s eta 0:03:39   | 494.6 MB 2.5 MB/s eta 0:01:59�████████▌           | 509.9 MB 2.3 MB/s eta 0:02:03��████████████████████▋          | 537.7 MB 2.3 MB/s eta 0:01:52     |███████████████████████████▉    | 692.5 MB 950 kB/s eta 0:01:50     |████████████████████████████    | 699.5 MB 860 kB/s eta 0:01:54     |█████████████████████████████▍  | 732.5 MB 2.9 MB/s eta 0:00:23    |█████████████████████████████▉  | 742.0 MB 1.4 MB/s eta 0:00:399 MB 2.1 MB/s eta 0:00:224 MB 2.6 MB/s eta 0:00:10\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.19.1-cp38-cp38-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 5.0 MB/s eta 0:00:01    | 4.0 MB 5.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/anubhav/.local/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/anubhav/.local/lib/python3.8/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/anubhav/.local/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/anubhav/.local/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/anubhav/.local/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 188 kB/s eta 0:00:01�███████████▉       | 18.4 MB 3.2 MB/s eta 0:00:0202�██▎    | 20.2 MB 4.4 MB/s eta 0:00:01��████    | 20.7 MB 4.4 MB/s eta 0:00:01��██████████████████████████  | 22.2 MB 4.4 MB/s eta 0:00:01 |██████████████████████████████▌ | 22.5 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 444 kB/s eta 0:00:01MB/s eta 0:00:08\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 3.8 kB/s eta 0:00:01                     | 25.8 MB 5.3 MB/s eta 0:01:12                | 103.0 MB 4.2 MB/s eta 0:01:15     |██████████████████▍             | 235.7 MB 5.8 MB/s eta 0:00:31[K     |██████████████████▋             | 238.2 MB 2.3 MB/s eta 0:01:16   |██████████████████▋             | 238.6 MB 2.3 MB/s eta 0:01:16��████████████████████▉          | 280.4 MB 4.5 MB/s eta 0:00:29��████████████████▊       | 317.2 MB 4.7 MB/s eta 0:00:217.5 MB 4.7 MB/s eta 0:00:20     |████████████████████████████    | 359.7 MB 2.9 MB/s eta 0:00:18��███████████████████▎   | 363.2 MB 3.1 MB/s eta 0:00:16████████▌   | 365.2 MB 1.7 MB/s eta 0:00:27█████████████████████████████▏  | 374.1 MB 5.5 MB/s eta 0:00:07█████████████████████████████▍  | 376.7 MB 2.6 MB/s eta 0:00:13    |█████████████████████████████▉  | 382.6 MB 2.2 MB/s eta 0:00:14�███████████████████████████▉  | 382.9 MB 2.2 MB/s eta 0:00:13�██████████████████████▉  | 383.4 MB 2.2 MB/s eta 0:00:13████████████████████  | 383.7 MB 2.2 MB/s eta 0:00:13��████████████████  | 384.0 MB 2.2 MB/s eta 0:00:13██████████████████████████████  | 385.2 MB 2.1 MB/s eta 0:00:13��██████████████████████████  | 385.5 MB 2.1 MB/s eta 0:00:13██████████████████████████████  | 386.3 MB 2.1 MB/s eta 0:00:1200:121 MB 3.9 MB/s eta 0:00:05�█████████████▋ | 393.4 MB 3.9 MB/s eta 0:00:05██████████████████████████████▊ | 393.7 MB 3.9 MB/s eta 0:00:05��█▊ | 394.0 MB 3.9 MB/s eta 0:00:05�██████████████████▊ | 394.3 MB 3.9 MB/s eta 0:00:052 MB 1.7 MB/s eta 0:00:08�██████████████ | 398.5 MB 1.7 MB/s eta 0:00:08███████████████████████████████ | 398.8 MB 1.7 MB/s eta 0:00:07��██ | 399.1 MB 1.7 MB/s eta 0:00:07  |███████████████████████████████▏| 399.4 MB 1.7 MB/s eta 0:00:07███████████████████████▏| 399.7 MB 1.7 MB/s eta 0:00:07██████████████▏| 400.0 MB 1.6 MB/s eta 0:00:07�█████████████████████████▊| 407.3 MB 6.4 MB/s eta 0:00:01�████████████████▊| 407.6 MB 6.4 MB/s eta 0:00:01�███████▉| 407.9 MB 6.4 MB/s eta 0:00:01███████▉| 408.6 MB 6.4 MB/s eta 0:00:01████████| 409.3 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 40 kB/s  eta 0:00:011/s eta 0:00:38��██              | 68.5 MB 2.3 MB/s eta 0:00:23| 87.9 MB 2.6 MB/s eta 0:00:13███████████████████████▎        | 88.3 MB 2.6 MB/s eta 0:00:13��█████████▎        | 88.6 MB 5.1 MB/s eta 0:00:07�███████████▊       | 94.1 MB 3.3 MB/s eta 0:00:09████████████████████▉       | 94.5 MB 3.3 MB/s eta 0:00:09\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 531 kB/s eta 0:00:01          | 26.1 MB 4.0 MB/s eta 0:00:08:00:47��███▌    | 48.6 MB 2.7 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 17 kB/s  eta 0:00:01    |████████████▋                   | 49.1 MB 2.2 MB/s eta 0:00:35/s eta 0:00:32��█▉              | 69.4 MB 1.5 MB/s eta 0:00:37��██              | 70.0 MB 1.5 MB/s eta 0:00:37MB/s eta 0:00:24██            | 77.3 MB 2.0 MB/s eta 0:00:24███████████████▏          | 82.2 MB 2.4 MB/s eta 0:00:18:00:09:00:094 MB/s eta 0:00:09.3 MB 4.1 MB/s eta 0:00:07███████████████████████▋      | 99.5 MB 4.1 MB/s eta 0:00:06�████████▎     | 101.9 MB 1.7 MB/s eta 0:00:133��████████▍     | 102.6 MB 1.7 MB/s eta 0:00:1313█████████▋     | 103.2 MB 1.7 MB/s eta 0:00:13:12 | 104.4 MB 1.7 MB/s eta 0:00:12████████████████████     | 104.7 MB 1.7 MB/s eta 0:00:12��████████▍    | 106.1 MB 1.2 MB/s eta 0:00:16    |█████████████████████████████▍  | 113.9 MB 4.4 MB/s eta 0:00:032 MB 2.3 MB/s eta 0:00:03████████| 123.8 MB 1.8 MB/s eta 0:00:0124.1 MB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 17 kB/s  eta 0:00:01B/s eta 0:00:47                  | 34.5 MB 3.5 MB/s eta 0:00:47��█▊                          | 34.8 MB 3.5 MB/s eta 0:00:46 eta 0:00:46 MB 2.9 MB/s eta 0:00:51��████▏                       | 50.3 MB 8.8 MB/s eta 0:00:17| 50.7 MB 8.8 MB/s eta 0:00:17 MB 2.8 MB/s eta 0:00:49██▌                   | 76.5 MB 4.6 MB/s eta 0:00:27          | 88.5 MB 7.3 MB/s eta 0:00:153 MB/s eta 0:00:15�███████████                | 97.7 MB 3.7 MB/s eta 0:00:27  | 98.1 MB 2.9 MB/s eta 0:00:34��███████▎              | 105.8 MB 3.1 MB/s eta 0:00:29    |█████████████████▍              | 106.2 MB 3.1 MB/s eta 0:00:2906.5 MB 3.1 MB/s eta 0:00:29��███████▌              | 107.3 MB 3.1 MB/s eta 0:00:29[K     |███████████████████             | 116.4 MB 4.4 MB/s eta 0:00:19   |███████████████████             | 116.8 MB 4.4 MB/s eta 0:00:19�███████▍            | 119.0 MB 4.0 MB/s eta 0:00:20�████████▉           | 127.7 MB 3.3 MB/s eta 0:00:21��████████████████████▍          | 131.1 MB 4.8 MB/s eta 0:00:14�█████████████▌          | 131.5 MB 4.8 MB/s eta 0:00:14��█████████████████████          | 134.3 MB 5.9 MB/s eta 0:00:11��█████████████████████          | 134.8 MB 5.9 MB/s eta 0:00:11██████████████████          | 134.9 MB 5.9 MB/s eta 0:00:11�██████████████          | 135.1 MB 5.9 MB/s eta 0:00:11MB 5.9 MB/s eta 0:00:11��████████▎         | 136.7 MB 5.9 MB/s eta 0:00:11     |██████████████████████▍         | 137.0 MB 5.9 MB/s eta 0:00:10MB 4.7 MB/s eta 0:00:12��████████▉         | 139.9 MB 4.7 MB/s eta 0:00:12     |███████████████████████         | 140.3 MB 4.7 MB/s eta 0:00:12MB 4.7 MB/s eta 0:00:12  |████████████████████████▏       | 147.7 MB 2.2 MB/s eta 0:00:22 | 161.1 MB 5.2 MB/s eta 0:00:07 | 164.9 MB 3.9 MB/s eta 0:00:09 | 165.8 MB 1.7 MB/s eta 0:00:18██████████████████████████▏    | 166.1 MB 1.7 MB/s eta 0:00:18�████▏    | 166.3 MB 1.7 MB/s eta 0:00:18��█████████████████████████▏    | 166.4 MB 1.7 MB/s eta 0:00:17�█████████████████████████▎    | 166.7 MB 1.7 MB/s eta 0:00:17��████████▍    | 168.0 MB 1.7 MB/s eta 0:00:17�████████▌    | 168.3 MB 1.7 MB/s eta 0:00:16K     |███████████████████████████▋    | 168.8 MB 1.7 MB/s eta 0:00:16     |███████████████████████████▋    | 169.1 MB 1.7 MB/s eta 0:00:16    |███████████████████████████▊    | 169.5 MB 1.7 MB/s eta 0:00:16��█████████    | 171.0 MB 7.0 MB/s eta 0:00:04�█████████    | 171.3 MB 7.0 MB/s eta 0:00:04█████████    | 171.6 MB 7.0 MB/s eta 0:00:04��████████    | 172.0 MB 7.0 MB/s eta 0:00:04��███████████████████▋   | 174.9 MB 3.2 MB/s eta 0:00:07████████▋   | 175.1 MB 3.2 MB/s eta 0:00:07|████████████████████████████▋   | 175.4 MB 3.2 MB/s eta 0:00:07█████████████████████████████▌  | 180.8 MB 2.3 MB/s eta 0:00:076 MB 3.4 MB/s eta 0:00:044 MB 3.2 MB/s eta 0:00:03█████▊ | 188.1 MB 3.2 MB/s eta 0:00:030 MB 3.2 MB/s eta 0:00:033 MB 3.2 MB/s eta 0:00:02███████▉| 195.1 MB 1.8 MB/s eta 0:00:0195.4 MB 1.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 176.2 MB 52 kB/s  eta 0:00:01             | 2.2 MB 4.1 MB/s eta 0:00:4314.5 MB 2.8 MB/s eta 0:00:58 MB 2.8 MB/s eta 0:00:48��█████                       | 49.9 MB 2.5 MB/s eta 0:00:50��████▌                     | 58.1 MB 3.6 MB/s eta 0:00:33            | 58.3 MB 3.6 MB/s eta 0:00:33██████████▋                     | 58.7 MB 3.6 MB/s eta 0:00:33MB/s eta 0:00:505 MB/s eta 0:00:100.5 MB/s eta 0:00:100.5 MB/s eta 0:00:10          | 78.0 MB 1.2 MB/s eta 0:01:21██████████▌                 | 79.8 MB 1.4 MB/s eta 0:01:12[K     |██████████████████▋             | 102.8 MB 2.5 MB/s eta 0:00:30     |██████████████████▊             | 103.0 MB 2.5 MB/s eta 0:00:30   | 107.7 MB 2.9 MB/s eta 0:00:24�███████▋            | 107.9 MB 2.9 MB/s eta 0:00:24MB 2.9 MB/s eta 0:00:24███████████████▊            | 108.6 MB 2.9 MB/s eta 0:00:24 eta 0:00:24�███████████▉            | 109.2 MB 2.9 MB/s eta 0:00:23    | 109.5 MB 3.0 MB/s eta 0:00:23████████████████████            | 109.9 MB 3.0 MB/s eta 0:00:23�████████▋           | 113.3 MB 4.3 MB/s eta 0:00:15█████████████████▎          | 117.1 MB 4.3 MB/s eta 0:00:14█████████████████▍          | 118.1 MB 3.7 MB/s eta 0:00:16��█████████▌          | 118.4 MB 3.7 MB/s eta 0:00:16��█████████████████████          | 120.6 MB 3.7 MB/s eta 0:00:16█▍         | 123.6 MB 6.4 MB/s eta 0:00:09MB 6.4 MB/s eta 0:00:09MB 6.4 MB/s eta 0:00:08█▉         | 125.5 MB 6.4 MB/s eta 0:00:08�████████████████▉         | 125.8 MB 6.4 MB/s eta 0:00:08MB 6.4 MB/s eta 0:00:08��█████████         | 126.9 MB 6.4 MB/s eta 0:00:08     |███████████████████████▏        | 127.3 MB 6.4 MB/s eta 0:00:08��██████████████████████▏        | 127.6 MB 5.3 MB/s eta 0:00:10█████▍        | 129.1 MB 5.3 MB/s eta 0:00:09  |███████████████████████▋        | 129.8 MB 5.3 MB/s eta 0:00:09  |███████████████████████▉        | 131.2 MB 5.3 MB/s eta 0:00:09��█████████████████████▉        | 131.6 MB 5.3 MB/s eta 0:00:09██████        | 132.6 MB 5.0 MB/s eta 0:00:09��████████████████▉       | 136.9 MB 3.7 MB/s eta 0:00:117.2 MB 3.7 MB/s eta 0:00:11 | 145.9 MB 1.2 MB/s eta 0:00:25��███████████████████▍   | 156.1 MB 3.0 MB/s eta 0:00:07��███████████████████▍   | 156.6 MB 3.0 MB/s eta 0:00:07████████▌   | 156.8 MB 3.0 MB/s eta 0:00:07.9 MB 3.0 MB/s eta 0:00:07��███████████████████▊   | 158.2 MB 3.0 MB/s eta 0:00:07.5 MB 3.0 MB/s eta 0:00:06��████████████████▉   | 158.8 MB 3.0 MB/s eta 0:00:06 MB/s eta 0:00:06��██████████████   | 159.4 MB 3.0 MB/s eta 0:00:06 0:00:02��███████████   | 160.0 MB 9.0 MB/s eta 0:00:02    |█████████████████████████████▋  | 163.1 MB 2.3 MB/s eta 0:00:06�███████████████████████████▊  | 163.5 MB 2.3 MB/s eta 0:00:06    |█████████████████████████████▊  | 163.8 MB 2.3 MB/s eta 0:00:06�███████████████████████████▉  | 164.1 MB 2.3 MB/s eta 0:00:06█████▎ | 166.5 MB 2.4 MB/s eta 0:00:059 MB 2.4 MB/s eta 0:00:044 MB 2.4 MB/s eta 0:00:04█████▋ | 168.9 MB 3.1 MB/s eta 0:00:034 MB 3.1 MB/s eta 0:00:03�█████████████▉ | 169.7 MB 3.1 MB/s eta 0:00:033 MB 3.1 MB/s eta 0:00:02██████ | 170.9 MB 3.1 MB/s eta 0:00:02███████▏| 171.5 MB 3.1 MB/s eta 0:00:02███████▎| 172.0 MB 4.2 MB/s eta 0:00:0272.3 MB 4.2 MB/s eta 0:00:01�█████████████████████████▍| 173.0 MB 4.2 MB/s eta 0:00:01�████████████████▌| 173.3 MB 4.2 MB/s eta 0:00:01�███████▌| 173.6 MB 4.2 MB/s eta 0:00:01173.9 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 782 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\"\n",
      "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.4 MB 25 kB/s  eta 0:00:011                  | 32.8 MB 6.3 MB/s eta 0:00:29��███                           | 33.3 MB 6.3 MB/s eta 0:00:29MB/s eta 0:00:33                  | 37.2 MB 5.3 MB/s eta 0:00:33     |█████▊                          | 37.7 MB 5.3 MB/s eta 0:00:33              | 66.2 MB 3.3 MB/s eta 0:00:44            | 70.2 MB 200 kB/s eta 0:11:34MB/s eta 0:00:44██▏                   | 79.8 MB 2.9 MB/s eta 0:00:44     |█████████████▉                  | 90.5 MB 1.1 MB/s eta 0:01:51�█████████████▎                | 100.0 MB 3.2 MB/s eta 0:00:35    |███████████████▊                | 102.9 MB 1.9 MB/s eta 0:00:56  | 105.8 MB 3.8 MB/s eta 0:00:28  | 106.9 MB 3.8 MB/s eta 0:00:27  | 107.4 MB 2.8 MB/s eta 0:00:37  | 108.0 MB 2.8 MB/s eta 0:00:37��███████▋              | 115.6 MB 3.0 MB/s eta 0:00:31    |█████████████████▊              | 115.9 MB 3.0 MB/s eta 0:00:3116.3 MB 3.0 MB/s eta 0:00:31  | 117.0 MB 3.0 MB/s eta 0:00:31[K     |███████████████████             | 123.8 MB 1.8 MB/s eta 0:00:48   |███████████████████             | 124.2 MB 1.8 MB/s eta 0:00:48   | 129.3 MB 3.0 MB/s eta 0:00:27   | 129.9 MB 4.1 MB/s eta 0:00:20�███████▉            | 130.1 MB 4.1 MB/s eta 0:00:20MB 4.1 MB/s eta 0:00:20████████████████            | 130.8 MB 4.1 MB/s eta 0:00:20█            | 131.2 MB 4.1 MB/s eta 0:00:2004.1 MB/s eta 0:00:20�████████▎           | 132.7 MB 4.1 MB/s eta 0:00:19�████████▍           | 133.4 MB 4.1 MB/s eta 0:00:19�████████▍           | 133.6 MB 4.1 MB/s eta 0:00:19�████████▋           | 135.0 MB 4.1 MB/s eta 0:00:190 MB 4.1 MB/s eta 0:00:18��█▉           | 136.3 MB 4.1 MB/s eta 0:00:18�█████████           | 137.6 MB 3.8 MB/s eta 0:00:19��█████████████████           | 138.0 MB 3.8 MB/s eta 0:00:19��          | 138.3 MB 3.8 MB/s eta 0:00:19 3.8 MB/s eta 0:00:19█████████████████▍          | 139.7 MB 3.8 MB/s eta 0:00:19��████████████████████▍          | 140.0 MB 3.8 MB/s eta 0:00:19��████████████████████▌          | 140.3 MB 3.8 MB/s eta 0:00:19��████████████████████▋          | 141.1 MB 3.6 MB/s eta 0:00:20��█████████████████████          | 144.2 MB 2.5 MB/s eta 0:00:26██████████████████          | 144.4 MB 2.5 MB/s eta 0:00:26��████████████████▏         | 144.8 MB 2.5 MB/s eta 0:00:262.5 MB/s eta 0:00:26��███████▎         | 145.4 MB 2.5 MB/s eta 0:00:26  |██████████████████████▎         | 145.8 MB 2.5 MB/s eta 0:00:26        | 146.1 MB 2.5 MB/s eta 0:00:26MB 2.5 MB/s eta 0:00:25MB 2.5 MB/s eta 0:00:25MB 2.5 MB/s eta 0:00:25��████████▌         | 147.5 MB 2.5 MB/s eta 0:00:25     |██████████████████████▋         | 147.8 MB 5.4 MB/s eta 0:00:12��         | 148.1 MB 5.4 MB/s eta 0:00:12███████████████▊         | 148.5 MB 5.4 MB/s eta 0:00:12MB 5.4 MB/s eta 0:00:12��████████▉         | 149.0 MB 5.4 MB/s eta 0:00:12MB 5.4 MB/s eta 0:00:12MB 5.4 MB/s eta 0:00:11��█████████         | 150.9 MB 5.4 MB/s eta 0:00:11:00:11 |███████████████████████▎        | 151.9 MB 5.4 MB/s eta 0:00:11�█████████████████████▎        | 152.3 MB 3.5 MB/s eta 0:00:17███████████████████▎        | 152.6 MB 3.5 MB/s eta 0:00:17��████████████████▍        | 152.9 MB 3.5 MB/s eta 0:00:17�██████████████▍        | 153.3 MB 3.5 MB/s eta 0:00:17████████████▌        | 153.6 MB 3.5 MB/s eta 0:00:17  |███████████████████████▉        | 155.9 MB 2.6 MB/s eta 0:00:21██████▏       | 158.3 MB 2.6 MB/s eta 0:00:20██████▎       | 159.1 MB 3.7 MB/s eta 0:00:149.3 MB 3.7 MB/s eta 0:00:14███████████████▍       | 159.6 MB 3.7 MB/s eta 0:00:14B 3.7 MB/s eta 0:00:14�█████████████▌       | 160.3 MB 3.7 MB/s eta 0:00:14██████▋       | 161.3 MB 3.7 MB/s eta 0:00:14    |████████████████████████▊       | 161.7 MB 3.7 MB/s eta 0:00:14�████▊       | 162.0 MB 3.7 MB/s eta 0:00:13��████████████████▉       | 162.6 MB 3.7 MB/s eta 0:00:13��█████████████████       | 163.1 MB 2.7 MB/s eta 0:00:18█████████████████████▏      | 164.5 MB 2.7 MB/s eta 0:00:17█████████████████████▏      | 164.8 MB 2.7 MB/s eta 0:00:17 MB 2.1 MB/s eta 0:00:19 | 171.2 MB 2.1 MB/s eta 0:00:19 | 171.5 MB 2.1 MB/s eta 0:00:19 | 171.8 MB 2.1 MB/s eta 0:00:18 | 172.1 MB 2.1 MB/s eta 0:00:18███████████████████▍     | 172.4 MB 2.1 MB/s eta 0:00:18  | 172.7 MB 2.1 MB/s eta 0:00:18�███████████████████▌     | 173.0 MB 2.1 MB/s eta 0:00:18 | 173.2 MB 2.1 MB/s eta 0:00:18███████████████████▌     | 173.5 MB 2.1 MB/s eta 0:00:18  | 173.9 MB 2.1 MB/s eta 0:00:17 | 174.2 MB 3.0 MB/s eta 0:00:12███████████████████▊     | 174.5 MB 3.0 MB/s eta 0:00:12  | 174.8 MB 3.0 MB/s eta 0:00:12�███████████████████▊     | 175.1 MB 3.0 MB/s eta 0:00:12   | 175.5 MB 3.0 MB/s eta 0:00:12��████████▍    | 179.2 MB 3.7 MB/s eta 0:00:09��████████▍    | 179.5 MB 3.7 MB/s eta 0:00:09��████████▌    | 179.9 MB 2.9 MB/s eta 0:00:11�████████▌    | 180.2 MB 2.9 MB/s eta 0:00:10████████▋    | 180.5 MB 2.9 MB/s eta 0:00:10��███████▋    | 180.8 MB 2.9 MB/s eta 0:00:10�███████▊    | 181.1 MB 2.9 MB/s eta 0:00:10[K     |███████████████████████████▉    | 182.0 MB 2.9 MB/s eta 0:00:10K     |███████████████████████████▉    | 182.3 MB 2.9 MB/s eta 0:00:10     |████████████████████████████    | 182.7 MB 2.9 MB/s eta 0:00:10��█████████    | 183.2 MB 2.9 MB/s eta 0:00:09�█████████    | 183.5 MB 2.9 MB/s eta 0:00:09█████████    | 183.8 MB 2.9 MB/s eta 0:00:09�█████████████████████▏   | 184.1 MB 4.6 MB/s eta 0:00:06| 184.4 MB 4.6 MB/s eta 0:00:06�██████████████████▎   | 184.7 MB 4.6 MB/s eta 0:00:06B 4.6 MB/s eta 0:00:06�███████████████▎   | 185.4 MB 4.6 MB/s eta 0:00:06s eta 0:00:06�████████████▍   | 186.0 MB 4.6 MB/s eta 0:00:060:06�█████████▌   | 186.6 MB 4.6 MB/s eta 0:00:05    |████████████████████████████▋   | 186.9 MB 4.6 MB/s eta 0:00:05�██████▋   | 187.2 MB 4.6 MB/s eta 0:00:05��██████████████████████████▊   | 187.5 MB 4.6 MB/s eta 0:00:05�███▊   | 187.9 MB 4.6 MB/s eta 0:00:05 eta 0:00:05████████████▉   | 188.3 MB 6.9 MB/s eta 0:00:04:04█████████▉   | 188.9 MB 6.9 MB/s eta 0:00:03   |█████████████████████████████   | 189.3 MB 6.9 MB/s eta 0:00:03███████   | 189.6 MB 6.9 MB/s eta 0:00:03�███████████████████████████   | 189.9 MB 6.9 MB/s eta 0:00:03████   | 190.2 MB 6.9 MB/s eta 0:00:03�████████████████████████████▏  | 190.5 MB 6.9 MB/s eta 0:00:03    |█████████████████████████████▏  | 190.7 MB 6.9 MB/s eta 0:00:03�███████████████████████████▏  | 191.0 MB 6.9 MB/s eta 0:00:03████████████████████████▎  | 191.3 MB 6.9 MB/s eta 0:00:03��████████████████████▎  | 191.6 MB 6.9 MB/s eta 0:00:03█████████████████████████████▍  | 192.1 MB 344 kB/s eta 0:00:51��█████████████████████████▍  | 192.4 MB 344 kB/s eta 0:00:50�██████████████████████▌  | 192.7 MB 344 kB/s eta 0:00:49███████████████████▌  | 193.0 MB 344 kB/s eta 0:00:48    |█████████████████████████████▌  | 193.2 MB 344 kB/s eta 0:00:47�███████████████████████████▋  | 193.5 MB 344 kB/s eta 0:00:46████████████████████████▋  | 193.8 MB 344 kB/s eta 0:00:46��████████████████████▊  | 194.1 MB 344 kB/s eta 0:00:45█████████████████████████████▊  | 194.6 MB 344 kB/s eta 0:00:43��█████████████████████████▉  | 194.9 MB 344 kB/s eta 0:00:42�██████████████████████▉  | 195.2 MB 344 kB/s eta 0:00:41████████████████████  | 195.5 MB 344 kB/s eta 0:00:41    |██████████████████████████████  | 195.7 MB 344 kB/s eta 0:00:40�████████████████████████████  | 196.0 MB 344 kB/s eta 0:00:39█████████████████████████  | 196.3 MB 344 kB/s eta 0:00:38��█████████████████████  | 196.6 MB 344 kB/s eta 0:00:371 kB/s eta 0:00:34███████████▏ | 197.4 MB 361 kB/s eta 0:00:33��███████████████████████████▎ | 197.7 MB 361 kB/s eta 0:00:33� | 198.0 MB 361 kB/s eta 0:00:322 MB 361 kB/s eta 0:00:31�█████████████▍ | 198.5 MB 361 kB/s eta 0:00:30██████████████████████████████▍ | 198.9 MB 361 kB/s eta 0:00:30��█▍ | 199.1 MB 361 kB/s eta 0:00:29█████▌ | 199.6 MB 361 kB/s eta 0:00:27��█████████████████████▋ | 200.0 MB 361 kB/s eta 0:00:26B/s eta 0:00:26██████████▋ | 200.6 MB 361 kB/s eta 0:00:258 MB 361 kB/s eta 0:00:24�█████████████▊ | 201.1 MB 361 kB/s eta 0:00:23██████████████████████████████▉ | 201.4 MB 361 kB/s eta 0:00:23�██████▉ | 201.7 MB 86.5 MB/s eta 0:00:01��███████████████ | 202.2 MB 86.5 MB/s eta 0:00:01MB 86.5 MB/s eta 0:00:01��███████████████████████ | 202.8 MB 86.5 MB/s eta 0:00:01█████ | 203.1 MB 86.5 MB/s eta 0:00:01�██ | 203.3 MB 86.5 MB/s eta 0:00:01 |███████████████████████████████▏| 203.6 MB 86.5 MB/s eta 0:00:01   |███████████████████████████████▏| 203.9 MB 86.5 MB/s eta 0:00:01     |███████████████████████████████▏| 204.2 MB 86.5 MB/s eta 0:00:01010:01:00:01 0:00:01�███████▌| 205.8 MB 311 kB/s eta 0:00:12206.1 MB 311 kB/s eta 0:00:1110██████████████████████████▋| 206.7 MB 311 kB/s eta 0:00:09�█████████████████████████▊| 207.2 MB 311 kB/s eta 0:00:07�████████████████▊| 207.5 MB 311 kB/s eta 0:00:06�███████▊| 207.8 MB 311 kB/s eta 0:00:05208.1 MB 311 kB/s eta 0:00:05███████▉| 208.3 MB 311 kB/s eta 0:00:0408.6 MB 311 kB/s eta 0:00:032��██████████████████████████| 209.2 MB 311 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/anubhav/.local/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/anubhav/.local/lib/python3.8/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/anubhav/.local/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/anubhav/.local/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 316 kB/s eta 0:00:01 MB 4.3 MB/s eta 0:00:058 MB 4.3 MB/s eta 0:00:05     | 3.0 MB 4.3 MB/s eta 0:00:04�██▋                          | 3.5 MB 4.3 MB/s eta 0:00:042 5.1 MB 9.7 MB/s eta 0:00:02    | 5.6 MB 9.7 MB/s eta 0:00:02  | 6.0 MB 9.7 MB/s eta 0:00:02 |██████████▌                     | 6.5 MB 9.7 MB/s eta 0:00:0200:02    |████████████                    | 7.4 MB 9.7 MB/s eta 0:00:02                  | 7.8 MB 9.7 MB/s eta 0:00:02                 | 8.2 MB 9.7 MB/s eta 0:00:02:00:02 9.0 MB 9.7 MB/s eta 0:00:02██████████████▎                | 9.4 MB 3.6 MB/s eta 0:00:03�█████▍               | 10.1 MB 3.6 MB/s eta 0:00:03��█▌              | 10.8 MB 3.6 MB/s eta 0:00:03�█▏             | 11.2 MB 3.6 MB/s eta 0:00:03ta 0:00:03     |███████████████████▍            | 11.9 MB 3.6 MB/s eta 0:00:0312.3 MB 3.6 MB/s eta 0:00:03     |████████████████████▌           | 12.7 MB 3.6 MB/s eta 0:00:02��███████████████████           | 13.0 MB 3.6 MB/s eta 0:00:02��          | 13.4 MB 3.6 MB/s eta 0:00:02 eta 0:00:03�████▍        | 14.4 MB 2.3 MB/s eta 0:00:03/s eta 0:00:03MB/s eta 0:00:03��█       | 15.4 MB 2.3 MB/s eta 0:00:02     |█████████████████████████▌      | 15.8 MB 2.3 MB/s eta 0:00:02�█████████████████      | 16.1 MB 2.3 MB/s eta 0:00:02██████████████████████████▋     | 16.4 MB 2.3 MB/s eta 0:00:02 MB 2.3 MB/s eta 0:00:02 |███████████████████████████▋    | 17.1 MB 2.3 MB/s eta 0:00:02████████████████████▏   | 17.4 MB 2.3 MB/s eta 0:00:02     |████████████████████████████▊   | 17.7 MB 2.3 MB/s eta 0:00:01███████████████████▋  | 18.3 MB 316 kB/s eta 0:00:05�███████▏ | 18.6 MB 316 kB/s eta 0:00:04██████████████▋ | 18.9 MB 316 kB/s eta 0:00:03�██████████████████████▏| 19.2 MB 316 kB/s eta 0:00:02�██▍| 19.4 MB 316 kB/s eta 0:00:02██████████████████████████████| 19.7 MB 316 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: fsspec, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, triton, torch, torchvision\n",
      "Successfully installed fsspec-2024.10.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 torchvision-0.19.1 triton-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd65dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76e466",
   "metadata": {},
   "source": [
    "### **Q6: How do you create a simple neural network in PyTorch?**\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a4f0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "print(model)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf81b7",
   "metadata": {},
   "source": [
    "### **Q7: How do you define a loss function and optimizer in PyTorch?**\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06adca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b2b77",
   "metadata": {},
   "source": [
    "### **Q8: How do you implement a custom loss function in PyTorch?**\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7506f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0400)\n"
     ]
    }
   ],
   "source": [
    "def custom_loss(output, target):\n",
    "    return torch.mean((output - target)**2)\n",
    "\n",
    "loss = custom_loss(torch.tensor([0.5, 0.7]), torch.tensor([0.3, 0.9]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd01a08",
   "metadata": {},
   "source": [
    "### **Q9: How do you save and load a TensorFlow model?**\n",
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973aafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "new_model = tf.keras.models.load_model('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
